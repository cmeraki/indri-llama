{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Llama Tokenizer - Step 1\n",
    "from transformers import MimiModel, AutoFeatureExtractor, AutoTokenizer\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "class TextTokenizer:\n",
    "    def __init__(self, name='Llama_tokenizer'):\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(name, legacy=False)\n",
    "        print(\"text vocab size\", self.tokenizer.vocab_size)\n",
    "\n",
    "    def encode(self, text: str):\n",
    "        tokens = self.tokenizer.encode(text)\n",
    "        return tokens\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        return self.tokenizer.decode(tokens)\n",
    "    \n",
    "class MimiTokenizer:\n",
    "    def __init__(self, device):    \n",
    "        self.device = device\n",
    "        self.model = MimiModel.from_pretrained(\"kyutai/mimi\")\n",
    "        self.model.to(device)\n",
    "        self.model.eval()\n",
    "        self.feature_extractor = AutoFeatureExtractor.from_pretrained(\"kyutai/mimi\", device=device)\n",
    "        self.sampling_rate = self.feature_extractor.sampling_rate\n",
    "        self.n_codebooks = 8\n",
    "        self.vocab_size = 2048\n",
    "\n",
    "    @torch.inference_mode()\n",
    "    def encode(self, waveform):\n",
    "        inputs = self.feature_extractor(raw_audio=waveform, \n",
    "                                        sampling_rate=self.sampling_rate, \n",
    "                                        return_tensors=\"pt\").to(self.device)\n",
    "            \n",
    "        output = self.model.encode(inputs[\"input_values\"], inputs[\"padding_mask\"], num_quantizers=self.n_codebooks)\n",
    "        tokens = output.audio_codes[0].cpu().numpy()\n",
    "        return tokens\n",
    "\n",
    "    def decode(self, tokens):\n",
    "        assert len(tokens.shape) == 2\n",
    "        tokens = torch.tensor(np.expand_dims(tokens, axis=0)).to(self.device)\n",
    "        output = self.model.decode(tokens)\n",
    "        waveform = output.audio_values.cpu()\n",
    "        return waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text vocab size 128000\n",
      "Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition\n",
      "[128000, 39628, 11, 304, 279, 1193, 5647, 449, 902, 584, 527, 520, 3118, 11920, 11, 44642, 505, 1455, 422, 539, 505, 682, 279, 19071, 323, 44948, 15609, 304, 279, 68033]\n",
      "<|begin_of_text|>Printing, in the only sense with which we are at present concerned, differs from most if not from all the arts and crafts represented in the Exhibition\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "tokenizer = TextTokenizer()\n",
    "with open('/home/subhash/.cache/indri/lj_speech/annotation/metadata.jsonl') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        text = data['raw_text']\n",
    "        tokens = tokenizer.encode(text)\n",
    "        print(text)\n",
    "        print(tokens)\n",
    "        print(tokenizer.decode(tokens))\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8, 100)\n",
      "[[ 995  572 1117 1069 1620   80 1134  715 1650 1532  937 1077 1352  749\n",
      "   577  670 1701 1762  570 1468  157  839 1457  181 1022 1037 1067 1132\n",
      "  1320 1607 1607  663 1779 1301 1618 1782  304 1219 1640 1196  505 1146\n",
      "   784  917 1708  922 1137 1358  126  832 1743  663 1544  835  337 1377\n",
      "  2024 1252 1260  304 1039 1640  797  262  663  384 2025 1774  178  129\n",
      "  1669  421 1519 1022 1562 1252 1782  304 1882 1721 1356   96  777  505\n",
      "   526 1146 1235  981 1708 1473 1358  502 1268  885 1558 1252 1260  304\n",
      "  1631 1565]\n",
      " [ 277 1224 1549 1138 1795  954 1155  172 1889 1591 1776  275  338  907\n",
      "   243 1111  440 1155 1349  696 1996  993 1046 1293 1624  389 1843  339\n",
      "  1056  243 1211  243  243  243 1717  632  641 1342  534  739  735   15\n",
      "  1623 1706  731  338  773  820  490 1211  243  243 1056  893 1139 1769\n",
      "   693  192  823  369 1777  648 1211 1211  243 1349  789  931  632 1203\n",
      "   285  457 1910  903  328 1579  420 1518   31  177 1940 1715 2028 1348\n",
      "  1576 1478  794 1866  254  823  369 1056 1504  683  514  254 2032 1987\n",
      "   866  438]\n",
      " [ 738  942 1310 1566 1025  942  828 1753   30  383 1315  279 1764 1685\n",
      "  1149  407 1202  896 1286  958  690 1789  886 1744  826  356   64 1795\n",
      "  1178 1149 1149 1559 1559 1559 1590 1992 1477 1970 1531 1974 1324  683\n",
      "   354   37 1544  790  437 1616  666 1697 1559 1149  783  506  993 1685\n",
      "  1531 1590 1120  666 1573 1264 1502 1559 1559  666 1590 1682 1680 1499\n",
      "   256  252  372 1610  217 1315 1386 1107 1375 1315 1346 1487 1187 1821\n",
      "  1987 1112 2024  823  438  964  323 1626  112  946  666 1527  790  658\n",
      "  1567  626]\n",
      " [1206 1132    2 1076  670 1003  524 1081  401  691  240    3  464 1794\n",
      "   114 1004  269 1883  850  899 1713  552 1353 1373 1417  222 1667 1918\n",
      "   142  114  290 1348 1348 1348 1776 1244 1101  405  678 1955  970 1544\n",
      "  1901  698 1303  749  928  254  840 1348 1348  164 1348  905  843  269\n",
      "   526  353 1690 1070 1464 1981  142 1348 1348 1697  522  597  733 1689\n",
      "   734  694 1446 1738  691  592  652 1028 1188 1063  905 1738 1769 1661\n",
      "  1789  745  912 1996 1954 1940   57  164  614  532 1003 1579 1491 1819\n",
      "   131 2010]\n",
      " [1889  360  130  320 1244  885  356  165  741 1691   56 1877 1956 1793\n",
      "  1736  722  517  210    3  471  465  165 1525  669 1768  349 1449 1449\n",
      "  1514 1015  581  915  581  267  323 1907 1936  648  318  217 1668 1338\n",
      "  1474  959  273  151   34 1201  581 1736 1736  581 1736  474  486  145\n",
      "  1773 1900 1388 1848 2005 1821  267  340 1736 2005 1767  818  217  204\n",
      "   525 1369  774  329 1449   16  667  412  273 1606 1514 1850  134  290\n",
      "   927  348   47 1339 1082 1032  840  581 1562 1875  287  581 1497 1196\n",
      "  1532  537]\n",
      " [ 579 1176 1049 1613  147 1425 1762 1535  837    6    6  770 1937 1893\n",
      "   347 1520  258    6  773 1933  538  892 1981 1897  629  258    6 1033\n",
      "   568  555 1572 1443 1443 1443  328  924 1760 1599  514  310 1864 1241\n",
      "   650 1535  935 1340 1519 1556 1739 1569 1569 1030 1572 1373 1209 1981\n",
      "   274 1775  895 1016  554  673  347 1569 1569  554  799  566 1337    6\n",
      "     6  501 1181  881    6 1332 1847 1069 1634    6 1055  937  799 1561\n",
      "   567  369 1131 1430  514 1560  969 1030  405  449  265  580 1836 1494\n",
      "  1704  307]\n",
      " [ 700 1577 1635 1472  796 1609  121  172 1649 1686 1277 1224 1400  982\n",
      "   976  540  447 1425 1787 1375  445  220  930 1112  188  264  652 1057\n",
      "  1238 1871 1509 1238 1871 1238   94  719  881 1738 1483 1939  660 1118\n",
      "  1412 1965  760 1067  709  246  666 1238  825 1871  825  572  177 1196\n",
      "  1483 1872 1575  887   84 1082 1238 1238 1978  993 1145 1345  393  381\n",
      "   801 2017 1188 1292  415  712 1469 1049 2015 1229 1013  291  705  310\n",
      "  1931  593 1777   92 1762 1697 1960 1512  675  865  866 1373 1338   42\n",
      "   819  752]\n",
      " [1113  186 1649   74  108  416 1115 1260 1528  865 1613  618  903 1606\n",
      "   568  139  360  661  151  271  238 1963  431  458  819 1156  872 1337\n",
      "  1551 1606 1606 2008 2008 1744  318  500 1844 1063 1434  188 1835  184\n",
      "   744  975   72  258  766 1027 1551 1744 2008 1606 2008 1933 1563 1134\n",
      "   492 1098  188  392 1186  662 1413 1744 2008 1868  843  730 1522  262\n",
      "  1446 1267  324 1296  829  611  723 1450  172 1418 1090 1412 1513 1129\n",
      "  1206 1624 1129 1013  776  388 1852 2008 1613  182  618  580  723 1255\n",
      "   568  151]]\n"
     ]
    }
   ],
   "source": [
    "# Mimi Tokeniser - Step 2\n",
    "import numpy as np\n",
    "mimi_tokens = np.load(\"/home/subhash/.cache/indri/lj_speech/tokens/mimi/LJ040-0046.npy\")\n",
    "print(mimi_tokens.shape)\n",
    "print(mimi_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([128995, 130325, 132834, 135350, 138081, 138819, 140988, 143449,\n",
       "       128572, 131272, 133038, 135276, 136552, 139416, 141865, 142522,\n",
       "       129117, 131597, 133406, 134146, 136322, 139289, 141923, 143985,\n",
       "       129069, 131186, 133662, 135220, 136512, 139853, 141760, 142410,\n",
       "       129620, 131843, 133121, 134814, 137436, 138387, 141084, 142444,\n",
       "       128080, 131002, 133038, 135147, 137077, 139665, 141897, 142752,\n",
       "       129134, 131203, 132924, 134668, 136548, 140002, 140409, 143451,\n",
       "       128715, 130220, 133849, 135225, 136357, 139775, 140460, 143596,\n",
       "       129650, 131937, 132126, 134545, 136933, 139077, 141937, 143864,\n",
       "       129532, 131639, 132479, 134835, 137883, 138246, 141974, 143201,\n",
       "       128937, 131824, 133411, 134384, 136248, 138246, 141565, 143949,\n",
       "       129077, 130323, 132375, 134147, 138069, 139010, 141512, 142954,\n",
       "       129352, 130386, 133860, 134608, 138148, 140177, 141688, 143239,\n",
       "       128749, 130955, 133781, 135938, 137985, 140133, 141270, 143942,\n",
       "       128577, 130291, 133245, 134258, 137928, 138587, 141264, 142904,\n",
       "       128670, 131159, 132503, 135148, 136914, 139760, 140828, 142475,\n",
       "       129701, 130488, 133298, 134413, 136709, 138498, 140735, 142696,\n",
       "       129762, 131203, 132992, 136027, 136402, 138246, 141713, 142997,\n",
       "       128570, 131397, 133382, 134994, 136195, 139013, 142075, 142487,\n",
       "       129468, 130744, 133054, 135043, 136663, 140173, 141663, 142607,\n",
       "       128157, 132044, 132786, 135857, 136657, 138778, 140733, 142574,\n",
       "       128839, 131041, 133885, 134696, 136357, 139132, 140508, 144299,\n",
       "       129457, 131094, 132982, 135497, 137717, 140221, 141218, 142767,\n",
       "       128181, 131341, 133840, 135517, 136861, 140137, 141400, 142794,\n",
       "       129022, 131672, 132922, 135561, 137960, 138869, 140476, 143155,\n",
       "       129037, 130437, 132452, 134366, 136541, 138498, 140552, 143492,\n",
       "       129067, 131891, 132160, 135811, 137641, 138246, 140940, 143208,\n",
       "       129132, 130387, 133891, 136062, 137641, 139273, 141345, 143673,\n",
       "       129320, 131104, 133274, 134286, 137706, 138808, 141526, 143887,\n",
       "       129607, 130291, 133245, 134258, 137207, 138795, 142159, 143942,\n",
       "       129607, 131259, 133245, 134434, 136773, 139812, 141797, 143942,\n",
       "       128663, 130291, 133655, 135492, 137107, 139683, 141526, 144344,\n",
       "       129779, 130291, 133655, 135492, 136773, 139683, 142159, 144344,\n",
       "       129301, 130291, 133655, 135492, 136459, 139683, 141526, 144080,\n",
       "       129618, 131765, 133686, 135920, 136515, 138568, 140382, 142654,\n",
       "       129782, 130680, 134088, 135388, 138099, 139164, 141007, 142836,\n",
       "       128304, 130689, 133573, 135245, 138128, 140000, 141169, 144180,\n",
       "       129219, 131390, 134066, 134549, 136840, 139839, 142026, 143399,\n",
       "       129640, 130582, 133627, 134822, 136510, 138754, 141771, 143770,\n",
       "       129196, 130787, 134070, 136099, 136409, 138550, 142227, 142524,\n",
       "       128505, 130783, 133420, 135114, 137860, 140104, 140948, 144171,\n",
       "       129146, 130063, 132779, 135688, 137530, 139481, 141406, 142520,\n",
       "       128784, 131671, 132450, 136045, 137666, 138890, 141700, 143080,\n",
       "       128917, 131754, 132133, 134842, 137151, 139775, 142253, 143311,\n",
       "       129708, 130779, 133640, 135447, 136465, 139175, 141048, 142408,\n",
       "       128922, 130386, 132886, 134893, 136343, 139580, 141355, 142594,\n",
       "       129137, 130821, 132533, 135072, 136226, 139759, 140997, 143102,\n",
       "       129358, 130868, 133712, 134398, 137393, 139796, 140534, 143363,\n",
       "       128126, 130538, 132762, 134984, 136773, 139979, 140954, 143887,\n",
       "       128832, 131259, 133793, 135492, 137928, 139809, 141526, 144080,\n",
       "       129743, 130291, 133655, 135492, 137928, 139809, 141113, 144344,\n",
       "       128663, 130291, 133245, 134308, 136773, 139270, 142159, 143942,\n",
       "       129544, 131104, 132879, 135492, 137928, 139812, 141113, 144344,\n",
       "       128835, 130941, 132602, 135049, 136666, 139613, 140860, 144269,\n",
       "       128337, 131187, 133089, 134987, 136678, 139449, 140465, 143899,\n",
       "       129377, 131817, 133781, 134413, 136337, 140221, 141484, 143470,\n",
       "       130024, 130741, 133627, 134670, 137965, 138514, 141771, 142828,\n",
       "       129252, 130240, 133686, 134497, 138092, 140015, 142160, 143434,\n",
       "       129260, 130871, 133216, 135834, 137580, 139135, 141863, 142524,\n",
       "       128304, 130417, 132762, 135214, 138040, 139256, 141175, 142728,\n",
       "       129039, 131825, 133669, 135608, 138197, 138794, 140372, 143522,\n",
       "       129640, 130696, 133360, 136125, 138013, 138913, 141370, 142998,\n",
       "       128797, 131259, 133598, 134286, 136459, 138587, 141526, 143749,\n",
       "       128262, 131259, 133655, 135492, 136532, 139809, 141526, 144080,\n",
       "       128663, 130291, 133655, 135492, 137928, 139809, 142266, 144344,\n",
       "       128384, 131397, 132762, 135841, 138197, 138794, 141281, 144204,\n",
       "       130025, 130837, 133686, 134666, 137959, 139039, 141433, 143179,\n",
       "       129774, 130979, 133778, 134741, 137010, 138806, 141633, 143066,\n",
       "       128178, 130680, 133776, 134877, 136409, 139577, 140681, 143858,\n",
       "       128129, 131251, 133595, 135833, 136396, 138246, 140669, 142598,\n",
       "       129669, 130333, 132352, 134878, 136717, 138246, 141089, 143782,\n",
       "       128421, 130505, 132348, 134838, 137561, 138741, 142305, 143603,\n",
       "       129519, 131958, 132468, 135590, 136966, 139421, 141476, 142660,\n",
       "       129022, 130951, 133706, 135882, 136521, 139121, 141580, 143632,\n",
       "       129562, 130376, 132313, 134835, 137641, 138246, 140703, 143165,\n",
       "       129252, 131627, 133411, 134736, 136208, 139572, 141000, 142947,\n",
       "       129782, 130468, 133482, 134796, 136859, 140087, 141757, 143059,\n",
       "       128304, 131566, 133203, 135172, 136604, 139309, 141337, 143786,\n",
       "       129882, 130079, 133471, 135332, 136465, 139874, 142303, 142508,\n",
       "       129721, 130225, 133411, 135207, 137798, 138246, 141517, 143754,\n",
       "       129356, 131988, 133442, 135049, 137706, 139295, 141301, 143426,\n",
       "       128096, 131763, 133583, 135882, 138042, 139177, 140579, 143748,\n",
       "       128777, 132076, 133283, 135913, 136326, 139039, 140993, 143849,\n",
       "       128505, 131396, 133917, 135805, 136482, 139801, 140598, 143465,\n",
       "       128526, 131624, 134083, 135933, 137119, 138807, 142219, 143542,\n",
       "       129146, 131526, 133208, 134889, 136540, 138609, 140881, 143960,\n",
       "       129235, 130842, 134120, 135056, 136239, 139371, 142065, 143465,\n",
       "       128981, 131914, 132919, 136140, 137531, 139670, 140380, 143349,\n",
       "       129708, 130302, 132534, 136098, 137274, 138754, 142050, 143112,\n",
       "       129473, 130871, 133060, 136084, 137224, 139800, 141985, 142724,\n",
       "       129358, 130417, 132419, 134201, 137032, 139209, 142248, 144188,\n",
       "       128502, 131104, 133722, 134308, 136773, 139270, 141800, 144344,\n",
       "       129268, 131552, 132208, 134758, 137754, 138645, 140963, 143949,\n",
       "       128885, 130731, 133042, 134676, 138067, 138689, 141153, 142518,\n",
       "       129558, 130562, 132762, 135147, 136479, 138505, 141154, 142954,\n",
       "       129252, 130302, 133623, 135723, 136773, 138820, 141661, 142916,\n",
       "       129260, 132080, 132886, 135635, 137689, 140076, 141626, 143059,\n",
       "       128304, 132035, 132754, 135963, 137388, 139734, 140330, 143591,\n",
       "       129631, 130914, 133663, 134275, 137724, 139944, 141107, 142904,\n",
       "       129565, 130486, 132722, 136154, 136729, 138547, 141040, 142487])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weave Tokens, codebook offset - Step 3\n",
    "def weave_tokens(tokens):\n",
    "    result = []\n",
    "    max_length = max(len(codebook) for codebook in tokens)\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        for codebook_index, codebook in enumerate(tokens):\n",
    "            if i < len(codebook):\n",
    "                offset = 2048 * codebook_index + 128000\n",
    "                result.append(codebook[i] + offset)                 \n",
    "    return np.array(result)\n",
    "\n",
    "weave_audio = weave_tokens(mimi_tokens.tolist())\n",
    "weave_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text vocab size 128000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/subhash/miniconda3/lib/python3.12/site-packages/transformers/models/mimi/modeling_mimi.py:163: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.register_buffer(\"padding_total\", torch.tensor(kernel_size - stride, dtype=torch.int64), persistent=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text vocab size: 128000, Audio vocab size: 2048\n",
      "Embedding table shape: (130048, 2048)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import json\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "llama_tokenizer = TextTokenizer()\n",
    "llama_model = AutoModel.from_pretrained('Llama_tokenizer/')\n",
    "\n",
    "mimi_tokenizer = MimiTokenizer(device=torch.device('cuda'))\n",
    "metadata_file = '/home/subhash/.cache/indri/lj_speech/annotation/metadata.jsonl'\n",
    "audio_token_dir = '/home/subhash/.cache/indri/lj_speech/tokens/mimi/'\n",
    "num_text_tokens = llama_tokenizer.tokenizer.vocab_size\n",
    "num_audio_tokens = mimi_tokenizer.vocab_size\n",
    "print(f\"Text vocab size: {num_text_tokens}, Audio vocab size: {num_audio_tokens}\")\n",
    "embedding_table = np.zeros((num_text_tokens + num_audio_tokens, llama_model.config.hidden_size), dtype=np.float32)\n",
    "\n",
    "for token_id in range(num_text_tokens):\n",
    "    embedding_table[token_id] = llama_model.get_input_embeddings()(torch.tensor([token_id])).squeeze().detach().numpy()\n",
    "for audio_file in os.listdir(audio_token_dir):\n",
    "    audio_tokens = np.load(os.path.join(audio_token_dir, audio_file))\n",
    "    for token in audio_tokens.astype(np.int32):\n",
    "        embedding_table[num_text_tokens + token] = np.random.normal(size=llama_model.config.hidden_size)\n",
    "\n",
    "text_data = []\n",
    "mimi_tokens = []\n",
    "with open(metadata_file, 'r') as f:\n",
    "    for line in f:\n",
    "        data = json.loads(line)\n",
    "        text_data.append(data['raw_text'])\n",
    "       \n",
    "        audio_token_file = os.path.join(audio_token_dir, f\"{data['id']}.npy\")\n",
    "        if os.path.exists(audio_token_file):\n",
    "            audio_tokens = np.load(audio_token_file)\n",
    "            mimi_tokens.append(audio_tokens)\n",
    "        else:\n",
    "            mimi_tokens.append(np.array([100] * 8))  \n",
    "\n",
    "text_tokens = [llama_tokenizer.encode(text) for text in text_data]\n",
    "print(f\"Embedding table shape: {embedding_table.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'EncodecFeatureExtractor' object has no attribute 'get_vocab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PreTrainedTokenizerFast\n\u001b[1;32m      3\u001b[0m llama_vocab \u001b[38;5;241m=\u001b[39m llama_tokenizer\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39mget_vocab()\n\u001b[0;32m----> 4\u001b[0m mimi_vocab \u001b[38;5;241m=\u001b[39m mimi_tokenizer\u001b[38;5;241m.\u001b[39mfeature_extractor\u001b[38;5;241m.\u001b[39mget_vocab()\n\u001b[1;32m      6\u001b[0m offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(llama_vocab)\n\u001b[1;32m      7\u001b[0m mimi_vocab_offset \u001b[38;5;241m=\u001b[39m {k: v \u001b[38;5;241m+\u001b[39m offset \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m mimi_vocab\u001b[38;5;241m.\u001b[39mitems()}\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'EncodecFeatureExtractor' object has no attribute 'get_vocab'"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedTokenizerFast\n",
    "\n",
    "llama_vocab = llama_tokenizer.tokenizer.get_vocab()\n",
    "mimi_vocab = mimi_tokenizer()\n",
    "\n",
    "offset = len(llama_vocab)\n",
    "mimi_vocab_offset = {k: v + offset for k, v in mimi_vocab.items()}\n",
    "\n",
    "merged_vocab = {**llama_vocab, **mimi_vocab_offset}\n",
    "\n",
    "tts_tokenizer = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=llama_tokenizer.tokenizer, \n",
    "    vocab=merged_vocab, \n",
    ")\n",
    "\n",
    "tts_tokenizer.save_pretrained(\"TTS_tokenizer\")\n",
    "\n",
    "print(\"TTS_tokenizer has been created and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66692]\n"
     ]
    }
   ],
   "source": [
    "# Combine the tokens - Step 5\n",
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('tokenizer')\n",
    "task_token = tokenizer.encode('[spkr_hifi_tts_9017]')\n",
    "print(task_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mimi_vocab \u001b[38;5;241m=\u001b[39m mimi_tokenizer\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mget_input_embeddings()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/transformers/modeling_utils.py:1873\u001b[0m, in \u001b[0;36mPreTrainedModel.get_input_embeddings\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1871\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m base_model\u001b[38;5;241m.\u001b[39mget_input_embeddings()\n\u001b[1;32m   1872\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1873\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
